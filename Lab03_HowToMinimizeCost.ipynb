{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to minimize cost\n",
    "\n",
    "__[Gradient descent algorithm]__\n",
    "\n",
    "- minimize cost function : 비용함수를 최소화 시키는 방법\n",
    "- It can be applied to more general function : _cost(W1, W2)_ : 변수가 여러개 있을 때 적용 가능\n",
    "\n",
    "---\n",
    "\n",
    "1) Start with initial guesses\n",
    "    - Start at 0,0 (or any other value - random)      # W는 초기값으로 특정값을 줘도 되고 랜덤으로 할당해도 O.K\n",
    "    - Keeping changing W and b a little bit to try and reduce cost(W, b)     # W, b를 계속해서 조금씩 줄여나가자.\n",
    "2) Each time you change the parameters, you select the gradient which reduces cost(W, b) the most possible.\n",
    "    - 기울기가 최소화 되는 것으로 선택하자.    \n",
    "3) Has an interesting property\n",
    "    - Where you start can determine which minimum you end up\n",
    "    \n",
    "---\n",
    "\n",
    "alpha는 일반적으로 작은 수(ex. 0.01, 0.001, ...)<br>\n",
    "가중치는 원래의 가중치에서 비용함수를 가중치에 의해 편미분한 후 alpha를 곱한 것을 빼면서 계속 업그레이드 시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.000 |   74.66667\n",
      "-2.429 |   54.85714\n",
      "-1.857 |   38.09524\n",
      "-1.286 |   24.38095\n",
      "-0.714 |   13.71429\n",
      "-0.143 |    6.09524\n",
      " 0.429 |    1.52381\n",
      " 1.000 |    0.00000\n",
      " 1.571 |    1.52381\n",
      " 2.143 |    6.09524\n",
      " 2.714 |   13.71429\n",
      " 3.286 |   24.38095\n",
      " 3.857 |   38.09524\n",
      " 4.429 |   54.85714\n",
      " 5.000 |   74.66667\n"
     ]
    }
   ],
   "source": [
    "## Cost function in pure Python\n",
    "\n",
    "X = np.array([1, 2, 3])\n",
    "Y = np.array([1, 2, 3])\n",
    "\n",
    "def cost_func(W, X, Y):\n",
    "    c = 0\n",
    "    for i in range(len(X)):\n",
    "        c += (W*X[i] - Y[i]) ** 2\n",
    "        \n",
    "    return c / len(X)\n",
    "\n",
    "for feed_W in np.linspace(-3, 5, num = 15):\n",
    "    curr_cost = cost_func(feed_W, X, Y)\n",
    "    print(\"{:6.3f} | {:10.5f}\".format(feed_W, curr_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.000 |   74.66667\n",
      "-2.429 |   54.85714\n",
      "-1.857 |   38.09524\n",
      "-1.286 |   24.38095\n",
      "-0.714 |   13.71429\n",
      "-0.143 |    6.09524\n",
      " 0.429 |    1.52381\n",
      " 1.000 |    0.00000\n",
      " 1.571 |    1.52381\n",
      " 2.143 |    6.09524\n",
      " 2.714 |   13.71429\n",
      " 3.286 |   24.38095\n",
      " 3.857 |   38.09524\n",
      " 4.429 |   54.85714\n",
      " 5.000 |   74.66667\n"
     ]
    }
   ],
   "source": [
    "## Cost function in Tensorflow\n",
    "\n",
    "X = np.array([1, 2, 3])\n",
    "Y = np.array([1, 2, 3])\n",
    "\n",
    "def cost_func2(W, X, Y):\n",
    "    hypothesis = W * X\n",
    "    return tf.reduce_mean(tf.square(hypothesis - y))\n",
    "\n",
    "W_values = np.linspace(-3, 5, num =15)\n",
    "cost_values = []\n",
    "\n",
    "for feed_W in W_values:\n",
    "    curr_costs = cost_func(feed_W, X, Y)\n",
    "    cost_values.append(curr_costs)\n",
    "    print(\"{:6.3f} | {:10.5f}\".format(feed_W, curr_costs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'W' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-36e6304cc9a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mgradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdescent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mW\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdescent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'W' is not defined"
     ]
    }
   ],
   "source": [
    "## Gradient Descent\n",
    "alpha = 0.01\n",
    "gradient = tf.reduce_mean(tf.multiply(tf.multiply(W, X)-Y, X))\n",
    "descent = W - tf.multiply(alpha, gradient)\n",
    "W.assign(descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 | 18829.7812 |  47.348293\n",
      "   10 |  3959.8613 |  22.254509\n",
      "   20 |   832.7499 |  10.746943\n",
      "   30 |   175.1255 |   5.469776\n",
      "   40 |    36.8285 |   3.049760\n",
      "   50 |     7.7449 |   1.939984\n",
      "   60 |     1.6287 |   1.431060\n",
      "   70 |     0.3425 |   1.197676\n",
      "   80 |     0.0720 |   1.090651\n",
      "   90 |     0.0151 |   1.041571\n",
      "  100 |     0.0032 |   1.019064\n",
      "  110 |     0.0007 |   1.008742\n",
      "  120 |     0.0001 |   1.004009\n",
      "  130 |     0.0000 |   1.001839\n",
      "  140 |     0.0000 |   1.000843\n",
      "  150 |     0.0000 |   1.000387\n",
      "  160 |     0.0000 |   1.000178\n",
      "  170 |     0.0000 |   1.000081\n",
      "  180 |     0.0000 |   1.000037\n",
      "  190 |     0.0000 |   1.000017\n",
      "  200 |     0.0000 |   1.000008\n",
      "  210 |     0.0000 |   1.000004\n",
      "  220 |     0.0000 |   1.000002\n",
      "  230 |     0.0000 |   1.000001\n",
      "  240 |     0.0000 |   1.000001\n",
      "  250 |     0.0000 |   1.000001\n",
      "  260 |     0.0000 |   1.000001\n",
      "  270 |     0.0000 |   1.000001\n",
      "  280 |     0.0000 |   1.000001\n",
      "  290 |     0.0000 |   1.000001\n"
     ]
    }
   ],
   "source": [
    "# 실제 활용\n",
    "\n",
    "tf.compat.v1.set_random_seed(0)     # for reproducibility : 다음에도 똑같이 재현하기 위해\n",
    "                                    # 1 버전에서는 tf.set_random_seed(seed)\n",
    "\n",
    "X = [1., 2., 3., 4.]\n",
    "Y = [1., 2., 3., 4.]\n",
    "\n",
    "W = tf.Variable(tf.random.normal([1], -100., 100.))   # 1 버전 : tf.random_normal\n",
    "\n",
    "for step in range(300):\n",
    "    hypothesis = W * X\n",
    "    cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "    \n",
    "    alpha = 0.01\n",
    "    gradient = tf.reduce_mean(tf.multiply(tf.multiply(W, X) - Y, X))\n",
    "    descent = W - tf.multiply(alpha, gradient)\n",
    "    W.assign(descent)\n",
    "    \n",
    "    if step % 10 == 0:\n",
    "        print(\"{:5} | {:10.4f} | {:10.6f}\".format(step, cost.numpy(), W.numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 |   120.0000 |   4.700000\n",
      "   10 |    25.2357 |   2.696754\n",
      "   20 |     5.3070 |   1.778102\n",
      "   30 |     1.1161 |   1.356824\n",
      "   40 |     0.2347 |   1.163633\n",
      "   50 |     0.0494 |   1.075039\n",
      "   60 |     0.0104 |   1.034412\n",
      "   70 |     0.0022 |   1.015781\n",
      "   80 |     0.0005 |   1.007237\n",
      "   90 |     0.0001 |   1.003319\n",
      "  100 |     0.0000 |   1.001522\n",
      "  110 |     0.0000 |   1.000698\n",
      "  120 |     0.0000 |   1.000320\n",
      "  130 |     0.0000 |   1.000147\n",
      "  140 |     0.0000 |   1.000067\n",
      "  150 |     0.0000 |   1.000031\n",
      "  160 |     0.0000 |   1.000014\n",
      "  170 |     0.0000 |   1.000006\n",
      "  180 |     0.0000 |   1.000003\n",
      "  190 |     0.0000 |   1.000001\n",
      "  200 |     0.0000 |   1.000001\n",
      "  210 |     0.0000 |   1.000001\n",
      "  220 |     0.0000 |   1.000001\n",
      "  230 |     0.0000 |   1.000001\n",
      "  240 |     0.0000 |   1.000001\n",
      "  250 |     0.0000 |   1.000001\n",
      "  260 |     0.0000 |   1.000001\n",
      "  270 |     0.0000 |   1.000001\n",
      "  280 |     0.0000 |   1.000001\n",
      "  290 |     0.0000 |   1.000001\n"
     ]
    }
   ],
   "source": [
    "# W를 특정한 값으로 설정했을 때\n",
    "\n",
    "tf.compat.v1.set_random_seed(0)     # for reproducibility : 다음에도 똑같이 재현하기 위해\n",
    "                                    # 1 버전에서는 tf.set_random_seed(seed)\n",
    "\n",
    "X = [1., 2., 3., 4.]\n",
    "Y = [1., 2., 3., 4.]\n",
    "\n",
    "W = tf.Variable([5.0])   # 1 버전 : tf.random_normal\n",
    "\n",
    "for step in range(300):\n",
    "    hypothesis = W * X\n",
    "    cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "    \n",
    "    alpha = 0.01\n",
    "    gradient = tf.reduce_mean(tf.multiply(tf.multiply(W, X) - Y, X))\n",
    "    descent = W - tf.multiply(alpha, gradient)\n",
    "    W.assign(descent)\n",
    "    \n",
    "    if step % 10 == 0:\n",
    "        print(\"{:5} | {:10.4f} | {:10.6f}\".format(step, cost.numpy(), W.numpy()[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
